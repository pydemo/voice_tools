In this lesson, you will learn how to leverage the multi-agent design to complete a task involving multiple steps. You will build a sequence of chats between multiple agents who collaborate to provide a fun customer onboarding experience for a product. You will also see how humans can be seamlessly involved in the loop of an AI system. Alright, let's code!

Let's consider a customer onboarding scenario. In this scenario, a typical procedure is to first collect some customer information, then survey the customer's interests, and finally engage with the customer based on the collected information. With this in mind, it’s a good idea to decompose this customer onboarding task into three subtasks: information collecting, interest survey, and customer engagement. Let's now see how we can complete this series of tasks with sequential chat.

We will use the `ConversibleAgent` class from AutoGen to realize these agents. First, let's import this `ConversibleAgent` from AutoGen. The first step is to create an onboarding agent that asks for personal information. We achieve this by setting a system message as a customer onboarding agent and providing detailed instructions. We set the human input mode as "never" because we are using a large language model to generate responses from this agent.

Next, we can create another onboarding agent that asks for topic preferences. Similarly, we configure this by setting the system message to ask for the customer's interest or preference on specific topics. Again, we use "never" as the human input mode and employ a large language model to support this conversible agent. The final agent we want to create is the Customer Engagement Agent, which provides fun facts, jokes, or interesting stories based on the customer's personal information and topic preference. We give detailed instructions on the behavior of this engagement agent through the appropriate system message.

Next, we should define a customer proxy agent to act as a stand-in for the real customer. Here, we set the human input mode to "always" so that this proxy agent can always solicit input from the real customer. With these agents constructed, we can now craft a sequential chat to complete the onboarding process. In this specific example, each chat is effectively a two-agent chat between a particular onboarding agent and the customer proxy agent. The sender agent initiates the conversation with a message to the recipient, and then they engage in back-and-forth conversation until the maximum number of transactions (max-trans) is reached or the termination message is received.

In the first chat, we set the max-trans to 2, allowing for at most two turns of conversation. In sequential chat scenarios, tasks typically depend on each other. Therefore, we may want to summarize information from the previous chat to be used in the next chat. In this case, we use the summary method. For example, we use reflection as the summary method to summarize the customer's personal information from the first chat and pass it to the second chat. We further add a summary prompt to instruct the large language model on how to perform the summary. Here, we instruct it to return the customer information in a JSON object format, including fields for name and location.

In the second chat, we follow a similar approach. The sender is the onboarding topic preference agent, and the recipient is the customer proxy agent. The kickoff message is, “Great, could you tell me what topics you are interested in reading about?” For the summary method, we use reflection with LRR. This time, we do not provide any customized summary prompt, so we use the built-in default prompt. The max-trans is set to one, as we just want one turn of conversation to determine the customer's topic of interest. In your specific case, you can adjust this to multiple transactions to gather more information.

In the third chat, the conversation is between the customer proxy agent and the customer engagement agent. This time, the customer proxy agent initiates the conversation with, “Let’s find something to read.” After constructing this chat session, we are ready to start the entire onboarding process by executing `initiate_chats`. 

In this example, you will act as the customer. When you are prompted for answers, type your response and press enter. Now, let's start the chat. The first chat is between the onboarding personal information agent and the customer proxy agent. The onboarding agent asks the customer for their name and location. For instance, let's use a fake name, Alice. Next, it asks for the location, and we’ll say New York.

Now, you can see that we are starting a new chat, the second chat session, between the topic preference agent and the customer proxy agent. The agent asks for topics the customer is interested in reading about. Let's say the customer wants to read about dogs. Now we enter the third chat session between the customer proxy agent and the customer engagement agent. The customer engagement agent uses the personal information, name, and location, along with the topic of interest, to provide engaging content.

Feel free to pause here and experiment by providing your own preferences. When the chat is done, you can review the results from each of these chat sessions in the sequential chat. For instance, we have a JSON format of the customer’s personal information, a summary of the customer’s interest (“Alice is interested in reading about dog-related topics”), and an engaging message for the customer. You can also check the cost associated with each chat session, including the total cost, prompt token cost, and completion token cost.

In this lesson, we have learned how to use sequential chats to complete a series of dependent tasks. In the next lesson, you will learn how to implement the reflection agentic design pattern with nested chats, where a chat or sequence of chats is nested within another chat as the inner monologue of an agent.