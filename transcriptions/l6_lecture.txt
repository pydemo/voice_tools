 In this last lesson, you will dive deeper into multi-agent group chats and build a custom group chat that collaborates to generate a detailed report on a stock's performance over the past month. Finishing this complex task involves planning, which is realized by including a planning agent in the group chat. You will also learn how to customize the speaker's transition into group chat. Let's dive into the code. Alright, in this lesson, we're going to learn about one last agentic design pattern, planning, and we're going to also learn a new conversation pattern called group chat. Okay, let's get started. First, let's define our LRM configuration to be using GPT-4 Turbo. Let's define our task. So this is a fairly complex task. In previous lessons, we learned about one conversation pattern called a sequential chat that can perform multi-step tasks. But that requires humans to design the concrete steps and the concrete agents involved in each step. What if we want to simplify the problem? What if we want to simply define agents and make them work together to solve this task without giving them the very specific detailed instructions for every step? How can I do that? In this lesson, let's try a new conversation pattern called group chat, which doesn't require manually designed steps. First, let's import autogen, and then try to create a few agents that are needed for this task. Let's think about what What do we need? Initially, we need a user proxy agent that can send other agents about this initial task. So we will define a conversable agent named admin, who will give it a system message about give the task and send instructions to writer to refine the blog post. And we'll set the code execution configuration to be false and give it a large-ranger model configuration and set a human input mode to be always. So this agent will always ask for human's input when it's its turn to speak. And if the human skips the input, it will send instructions to some writer agent to refine the blog post. Let's think about what other agents do we need. Since this is a complex task, we probably need a planning agent that can help us decompose the task to simpler, smaller tasks and send those subtasks to other agents to solve them. So how about we create a planner agent? This is a conversable agent with the name planner. We give it some instructions. Given a task, please determine what information is needed to complete the task. Please note that the information will all be retrieved using Python code. Please only suggest information that can be retrieved using Python code. After each step is done by others, check the progress and instruct the remaining steps. If a step fails, try to work around. You also see I'm adding a field called description. What's the difference between the description and system message? The system message is an instruction I'm telling the agent only, and only this agent needs to know. And for the description, I am using that for letting other agents know about the role of this agent. and, for example, a manager could decide when to use this agent based on the description. So the description is planner, giving a task, determining what information is needed to complete the task. After each step is done by others, check the progress and instruct the remaining steps. So it's less detailed but more high-level and from a different third-person point of view, we can know what this agent is about. And we also give it the large-order model configuration. So the planner might suggest some tasks that require using Python code. So we might need some agent that's capable of writing Python code. So let's define an agent called engineer, and we're going to use the default assistant agent from Autogen as a class for this agent. This default assistant agent will have a default system message about the detailed instructions for writing code. So we don't need to provide an additional system message, but we will add a description saying that this is an engineer that writes code based on the plan provided by the planner. After the engineer writes code, we need some agent to execute code. So we probably need an executor. So this is a conversable agent with code execution configuration. So we will set the last end messages to be three. So this agent will look back in the conversation history and find the first message that contains code and execute code in that message. We set the work direction to be coding and we set useDocker to be false. Don't forget the task is about writing blog posts. So we also need an agent that is in charge of writing. So we define this writer agent with this message. Please write blogs in markdown format with relevant titles and put content in the markdown code blog. and it will also tell it to take feedback from the admin and refine the blog. And we need to provide the description as well. Okay, so now we have created these agents. You can see that when creating each agent, I mainly think about what role this agent needs to play and to solve this task, what are some of the roles I need to create these agents. But I don't need to provide detailed instructions about which agent should do what first. I simply put them together in the group chat. Here I'm creating a group chat with the agents I just created. There are five agents of them. I provide some empty initial message list and set the next round to be 10. That's all I need. Before I make these agents work, I need to create a group chat manager. That's a special agent in AutoGen to manage this group chat. This group chat manager also needs a large-ranger model configuration. So I simply define these agents and put these in the group chat. And then I can start the conversation by initiating a chat between the user proxy and the manager. Because the first message I want it to be from user proxy. And the message content will be the task we defined earlier. Try that. So after I start the conversation, all these agents will automatically work together. and there's no need to specify a particular speak order from the developer. The first message will be sent from the admin, the user proxy, to the chat manager about the task. And the chat manager will broadcast this message to every other agent. So every agent in the group chat will see this message and then the chat manager will pick one agent to speak next using its large-angle model. And when deciding who to speak next, The chat manager will look at the current conversation history and the roles of each agent and decide which one is the best. So we see that the planner is picked as the first agent to speak. Okay, so planner is suggesting a few steps, including retrieve the stock data, analyze the stock data, research contextual events, draft a blog post, and in the last, reiterate on step one and suggest some actions. Again, the chat manager now needs to pick the next speaker. It picks engineer. So the engineer will follow the suggestion by the planner of the first step and suggest a code to retrieve the stock data. Next, the executor is picked by the chat manager to execute the code and output the data. And now the planner is picked again by the chat manager after the first step is finished. So it's suggesting the next steps about analyzing stock data, research contextual events, etc. So it actually suggests one Python code example to get started with the second step. So the engineer will complete that Python code about this stock data analysis, and the executor is picked by the chain manager to run the code and output the result. the result. You can see not only the stock price is output, but also the daily change. And when the first two steps are finished, we see that the writer is picked by the chat manager to start drafting the blog post, because the writer already has good enough information to begin writing. So it writes the blog post in a markdown format. It has an introduction section, analysis of stock price, a stock performance section, significant events and their impact and conclusion. Now the admin is picked by the chat manager. So this admin will ask for user feedback. If I'm not satisfied with this blog post, I can provide my input. Here I'm going to skip my feedback and let this user proxy agent to suggest some change on behalf of myself. Now this user proxy agent is using that general model to come up with a reply. This reply should contain some suggestions about what needs to be improved in this blog post. So the admin comes up with some refinements, including adding visuals, detailed analysis, interactive elements, and so on. So after that, the writer is supposed to take that feedback and automatically suggest a refined blog post. So we see that during this conversation, all the agents are triggered automatically by the group chat manager and following the predefined roles and descriptions. Usually the roles and descriptions need to be carefully designed to make sure they can follow the right order. And okay, now we see that the writer has made some revision to the blog post. It also summarized the enhanced elements in the blog post. If we increase the round in this group chat, there can be more conversations. And the conversation stops here because we set the next round to be 10. So if we review this conversation, we will find that the planner does play the role of suggesting an initial plan. And after some steps are finished, it will review the progress and suggest follow-up steps. But not all the steps are followed exactly. After the first two steps, I think the writer skipped the third step and started writing the blog post. This is the downside of using the librarian model to decide the speaker order always. But there are a few ways you could add more control to the conversation. For example, you could set constraints about the speaker's order. I'll show you how to do that. First, let's repeat the same definition of agents. So these are the same agents I used. I'll define them again, and I'll demonstrate how to add some constraints in the speaker order. So in this example, I create a group chat with additional constraints. This is a dictionary called allowed or disallowed speaker transitions. For each agent, you could specify which agent is allowed to speak after this particular agent. For example, we restrict the speaker after engineer to be either user proxy or executor. And we restrict the speaker after the executor to be either user proxy or engineer or planner. So after we impose this constraint, we're not supposed to see the writer to follow up executor agent immediately. So that gives the planner a chance to review the plan before the writer starts writing the blog post. You could either specify allowed or disallowed speaker transitions. In this case, we're setting only allowed transitions. Execute that. So after defining that, we're supposed to see a speak order that conforms better with our desire. The first few steps are the same, but now after the executor finished the second step, we're supposed to see the planner take over, interview the previous steps, and suggest the next steps. So this fixes the problem I mentioned earlier. You can see that although we added some constraints, the overall task completion is still nonlinear. So it still keeps the flexibility of having some agent back-end force and chiming when they need to. So this still has more flexibility than the sequential chat. And this way of specifying the speaker transitions can simulate the finance state machine transition in the group chat. So it's an advanced functionality to allow developers to add more control. You could also add some natural language instructions in the descriptions of the agents so that you not only specify the constraint, but also have more details about when to translate to which agent. And in addition, you could also define a precise translation order using programming language. I will not cover that in this lesson, but you can find that information from Autogen's website. To summarize, group chat provides a more dynamic way for multiple agents to solve a task together and without human developers to design a very detailed plan for execution. You could also add some planner agent for helping with making plans and task decomposition. In general, there can be multiple different ways for doing task decomposition and planning, and we only showed one particular example. That's all the lessons we covered about the basic introduction to Autogen. There are many other advanced functionalities in Autogen, such as teaching agents to improve over time, having multi-modality, having vision capability to understand images, using OpenAI Assistant as a backend for agents, and so on and so forth. We also have agent-based evaluation tools and benchmarking tools and other new interesting research, for example, helping users design agents for a particular task. Please find those advanced new features or ongoing research from our website and read the blog posts. We hope you enjoyed the lessons so far and hope you explore many more interesting use cases with your own experience. Thank you.